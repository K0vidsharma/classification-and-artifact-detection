{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10120154,"sourceType":"datasetVersion","datasetId":6244463},{"sourceId":10120277,"sourceType":"datasetVersion","datasetId":6244566}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport json\nfrom PIL import Image\nfrom transformers import CLIPProcessor, CLIPModel\n\n# Load the CLIP model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n# List of artifacts to check\nartifact_list = [\n    \"Anatomically incorrect paw structures\",\n    \"Impossible foreshortening in animal bodies\",\n    \"Anatomically impossible joint configurations\",\n    \"Misaligned body panels\",\n    \"Cinematization Effects\",\n    \"Artificial smoothness\",\n    \"Movie-poster like composition of ordinary scenes\",\n    \"Exaggerated characteristic features\",\n    \"Incorrect Skin Tones\",\n    \"Synthetic material appearance\",\n    \"Inconsistent shadow directions\",\n    \"Multiple light source conflicts\",\n    \"Multiple inconsistent shadow sources\",\n    \"Dramatic lighting that defies natural physics\",\n    \"Distorted window reflections\",\n    \"Ghosting effects: Semi-transparent duplicates of elements\",\n    \"Regular grid-like artifacts in textures\",\n    \"Repeated element patterns\",\n    \"Scale inconsistencies within the same object class\",\n    \"Unrealistic specular highlights\",\n    \"Spatial relationship errors\",\n    \"Aliasing along high-contrast edges\",\n    \"Artificial enhancement artifacts\",\n    \"Unnatural pose artifacts\",\n    \"Color coherence breaks\",\n    \"Unnatural color transitions\",\n    \"Discontinuous surfaces\",\n    \"Floating or disconnected components\",\n    \"Irregular proportions in mechanical components\",\n    \"Abruptly cut off objects\",\n    \"Impossible mechanical connections\",\n    \"Inconsistent scale of mechanical parts\",\n    \"Physically impossible structural elements\",\n    \"Scale inconsistencies within single object\"\n]\n\n# Function to analyze a single image for artifacts and return results\ndef analyze_single_image(image_path):\n    # Load, resize, and preprocess the image\n    image = Image.open(image_path).convert(\"RGB\").resize((32, 32))\n    inputs = processor(text=artifact_list, images=image, return_tensors=\"pt\", padding=True).to(device)\n\n    # Get similarity scores from CLIP\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image  # Shape: (1, len(artifact_list))\n    scores = logits_per_image.softmax(dim=1).squeeze()  # Convert to probabilities\n\n    # Select the top artifacts based on a threshold\n    threshold = 0.05  # Adjust based on desired sensitivity\n    detected_artifacts = [\n        artifact_list[i] for i in range(len(artifact_list)) if scores[i] > threshold\n    ]\n\n    return detected_artifacts\n\n# Load predictions from the given JSON file\ndef load_predictions(json_file_path):\n    with open(json_file_path, 'r') as file:\n        predictions = json.load(file)\n    print(f\"Loaded predictions: {predictions[:5]}\")  # Print first 5 entries to verify structure\n    return predictions\n\n# Filter predictions to include only \"fake\" images\ndef filter_fake_predictions(predictions):\n    fake_predictions = [entry for entry in predictions if entry[\"prediction\"].lower() == \"fake\"]\n    print(f\"Fake predictions: {fake_predictions}\")  # Print first 5 fake predictions for verification\n    return fake_predictions\n\n# Function to analyze images with \"fake\" predictions and save results to JSON\ndef analyze_fake_images(directory_path, fake_predictions, output_json_path):\n    results = []\n    \n    # Loop through the predictions that are \"fake\"\n    for entry in fake_predictions:\n        image_index = entry[\"index\"]\n        filename = f\"{image_index}.png\"  # Modify as per your filename format\n        file_path = os.path.join(directory_path, filename)\n        \n        # Skip if the image doesn't exist\n        if not os.path.exists(file_path):\n            continue\n        \n        # Analyze the image for artifacts\n        detected_artifacts = analyze_single_image(file_path)\n        \n        # Add to results if artifacts are detected\n        if detected_artifacts:\n            results.append({\n                \"index\": image_index,  # Use the index from the prediction\n                \"explanation\": detected_artifacts  # Only include the artifact names and explanations\n            })\n    \n    # Save results to JSON file\n    if results:\n        with open(output_json_path, 'w') as json_file:\n            json.dump(results, json_file, indent=4)\n        print(f\"Results saved to {output_json_path}\")\n    else:\n        print(\"No results to save.\")\n\n# Example usage\ninput_predictions_json = \"/kaggle/input/submission-json/json.json\"  # Path to your prediction JSON file\ndirectory_path = \"/kaggle/input/adobe-test/perturbed_images_32\"  # Replace with your directory path\noutput_json_path = \"/kaggle/working/file1.json\"  # Output path for the results\n\n# Load and filter predictions\npredictions = load_predictions(input_predictions_json)\nfake_predictions = filter_fake_predictions(predictions)\n\n# Analyze fake images and save results\nanalyze_fake_images(directory_path, fake_predictions, output_json_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:32:51.407266Z","iopub.execute_input":"2024-12-06T13:32:51.407652Z","iopub.status.idle":"2024-12-06T13:32:56.314736Z","shell.execute_reply.started":"2024-12-06T13:32:51.407622Z","shell.execute_reply":"2024-12-06T13:32:56.313835Z"}},"outputs":[{"name":"stdout","text":"Loaded predictions: [{'index': 176, 'prediction': 'real'}, {'index': 88, 'prediction': 'fake'}, {'index': 162, 'prediction': 'fake'}, {'index': 189, 'prediction': 'real'}, {'index': 77, 'prediction': 'real'}]\nFake predictions: [{'index': 88, 'prediction': 'fake'}, {'index': 162, 'prediction': 'fake'}, {'index': 215, 'prediction': 'fake'}, {'index': 62, 'prediction': 'fake'}, {'index': 76, 'prediction': 'fake'}, {'index': 163, 'prediction': 'fake'}, {'index': 89, 'prediction': 'fake'}, {'index': 175, 'prediction': 'fake'}, {'index': 48, 'prediction': 'fake'}, {'index': 217, 'prediction': 'fake'}, {'index': 202, 'prediction': 'fake'}, {'index': 216, 'prediction': 'fake'}, {'index': 49, 'prediction': 'fake'}, {'index': 75, 'prediction': 'fake'}, {'index': 158, 'prediction': 'fake'}, {'index': 65, 'prediction': 'fake'}, {'index': 71, 'prediction': 'fake'}, {'index': 206, 'prediction': 'fake'}, {'index': 207, 'prediction': 'fake'}, {'index': 213, 'prediction': 'fake'}, {'index': 70, 'prediction': 'fake'}, {'index': 58, 'prediction': 'fake'}, {'index': 165, 'prediction': 'fake'}, {'index': 167, 'prediction': 'fake'}, {'index': 8, 'prediction': 'fake'}, {'index': 72, 'prediction': 'fake'}, {'index': 66, 'prediction': 'fake'}, {'index': 205, 'prediction': 'fake'}, {'index': 211, 'prediction': 'fake'}, {'index': 238, 'prediction': 'fake'}, {'index': 210, 'prediction': 'fake'}, {'index': 204, 'prediction': 'fake'}, {'index': 199, 'prediction': 'fake'}, {'index': 67, 'prediction': 'fake'}, {'index': 166, 'prediction': 'fake'}, {'index': 98, 'prediction': 'fake'}, {'index': 129, 'prediction': 'fake'}, {'index': 115, 'prediction': 'fake'}, {'index': 101, 'prediction': 'fake'}, {'index': 14, 'prediction': 'fake'}, {'index': 28, 'prediction': 'fake'}, {'index': 276, 'prediction': 'fake'}, {'index': 114, 'prediction': 'fake'}, {'index': 128, 'prediction': 'fake'}, {'index': 102, 'prediction': 'fake'}, {'index': 274, 'prediction': 'fake'}, {'index': 249, 'prediction': 'fake'}, {'index': 113, 'prediction': 'fake'}, {'index': 264, 'prediction': 'fake'}, {'index': 110, 'prediction': 'fake'}, {'index': 104, 'prediction': 'fake'}, {'index': 299, 'prediction': 'fake'}, {'index': 108, 'prediction': 'fake'}, {'index': 281, 'prediction': 'fake'}, {'index': 295, 'prediction': 'fake'}, {'index': 294, 'prediction': 'fake'}, {'index': 280, 'prediction': 'fake'}, {'index': 257, 'prediction': 'fake'}, {'index': 34, 'prediction': 'fake'}, {'index': 137, 'prediction': 'fake'}, {'index': 36, 'prediction': 'fake'}, {'index': 296, 'prediction': 'fake'}, {'index': 240, 'prediction': 'fake'}, {'index': 37, 'prediction': 'fake'}, {'index': 23, 'prediction': 'fake'}, {'index': 122, 'prediction': 'fake'}, {'index': 27, 'prediction': 'fake'}, {'index': 33, 'prediction': 'fake'}, {'index': 250, 'prediction': 'fake'}, {'index': 278, 'prediction': 'fake'}, {'index': 293, 'prediction': 'fake'}, {'index': 286, 'prediction': 'fake'}, {'index': 245, 'prediction': 'fake'}, {'index': 251, 'prediction': 'fake'}, {'index': 32, 'prediction': 'fake'}, {'index': 119, 'prediction': 'fake'}, {'index': 18, 'prediction': 'fake'}, {'index': 253, 'prediction': 'fake'}, {'index': 284, 'prediction': 'fake'}, {'index': 246, 'prediction': 'fake'}, {'index': 31, 'prediction': 'fake'}, {'index': 118, 'prediction': 'fake'}, {'index': 130, 'prediction': 'fake'}, {'index': 143, 'prediction': 'fake'}, {'index': 42, 'prediction': 'fake'}, {'index': 194, 'prediction': 'fake'}, {'index': 208, 'prediction': 'fake'}, {'index': 181, 'prediction': 'fake'}, {'index': 195, 'prediction': 'fake'}, {'index': 57, 'prediction': 'fake'}, {'index': 156, 'prediction': 'fake'}, {'index': 96, 'prediction': 'fake'}, {'index': 168, 'prediction': 'fake'}, {'index': 69, 'prediction': 'fake'}, {'index': 197, 'prediction': 'fake'}, {'index': 222, 'prediction': 'fake'}, {'index': 237, 'prediction': 'fake'}, {'index': 182, 'prediction': 'fake'}, {'index': 40, 'prediction': 'fake'}, {'index': 169, 'prediction': 'fake'}, {'index': 151, 'prediction': 'fake'}, {'index': 93, 'prediction': 'fake'}, {'index': 78, 'prediction': 'fake'}, {'index': 2, 'prediction': 'fake'}, {'index': 50, 'prediction': 'fake'}, {'index': 232, 'prediction': 'fake'}, {'index': 51, 'prediction': 'fake'}, {'index': 45, 'prediction': 'fake'}, {'index': 193, 'prediction': 'fake'}, {'index': 178, 'prediction': 'fake'}, {'index': 150, 'prediction': 'fake'}, {'index': 144, 'prediction': 'fake'}, {'index': 191, 'prediction': 'fake'}, {'index': 185, 'prediction': 'fake'}, {'index': 1, 'prediction': 'fake'}, {'index': 47, 'prediction': 'fake'}, {'index': 224, 'prediction': 'fake'}, {'index': 46, 'prediction': 'fake'}, {'index': 184, 'prediction': 'fake'}, {'index': 190, 'prediction': 'fake'}, {'index': 91, 'prediction': 'fake'}, {'index': 153, 'prediction': 'fake'}]\nResults saved to /kaggle/working/file1.json\n","output_type":"stream"}],"execution_count":19}]}